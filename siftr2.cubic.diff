diff --git a/siftr2.c b/siftr2.c
index eca1053..e962a4e 100644
--- a/siftr2.c
+++ b/siftr2.c
@@ -78,6 +78,7 @@
 #include <netinet/tcp_var.h>
 #include <netinet/tcp_hpts.h>
 #include <netinet/cc/cc.h>
+#include <netinet/cc/cc_cubic.h>
 #include <netinet/cc/cc_newreno.h>
 #include <netinet/tcp_stacks/sack_filter.h>
 #include <netinet/tcp_stacks/tcp_rack.h>
@@ -101,7 +102,7 @@ enum {
 	 * add new data fields such that the line length could exceed the below
 	 * value.
 	 */
-	MAX_LOG_MSG_LEN = 200, SIFTR_ALQ_BUFLEN = (1000 * MAX_LOG_MSG_LEN),
+	MAX_LOG_MSG_LEN = 300, SIFTR_ALQ_BUFLEN = (1000 * MAX_LOG_MSG_LEN),
 };
 
 static MALLOC_DEFINE(M_SIFTR, "siftr2", "dynamic memory used by SIFTR");
@@ -158,6 +159,11 @@ struct pkt_node {
 	tcp_seq			th_ack;
 	/* the length of TCP segment payload in bytes */
 	uint32_t		data_sz;
+	/* function name that updated cwnd */
+	char			fun_name[30];
+	/* line number that updated cwnd */
+	int			line;
+	struct cubic		cubic_data;
 	/* Link to next pkt_node in the list. */
 	STAILQ_ENTRY(pkt_node)	nodes;
 };
@@ -177,7 +183,11 @@ struct flow_info
 	enum {
 		FBSD = 0,
 		RACK = 1,
-	}		stack_type;
+	}		stack_type;		/* net stack name: freebsd or rack */
+	enum {
+		CUBIC = 0,
+		NEWRENO = 1,
+	}		tcp_cc;			/* TCP congestion control name */
 	uint32_t	mss;			/* Max Segment Size (bytes). */
 	u_char		sack_enabled;		/* Is SACK enabled? */
 	u_char		snd_scale;		/* Window scaling for snd window. */
@@ -376,7 +386,7 @@ siftr_process_pkt(struct pkt_node * pkt_node, char *buf)
 	 * cc xxx: check vasprintf()? */
 	ret_sz = sprintf(buf,
 	    "%c,%jd.%06ld,%u,%u,%u,%u,%u,%u,%u,%u,%u,%u,%u,%u,%u,%u,%u,%u,%u,"
-	    "%u,%u\n",
+	    "%u,%u,%s,%d,%u,%u,%u\n",
 	    direction[pkt_node->direction],
 	    (intmax_t)pkt_node->tval.tv_sec,
 	    pkt_node->tval.tv_usec,
@@ -398,7 +408,12 @@ siftr_process_pkt(struct pkt_node * pkt_node, char *buf)
 	    pkt_node->t_segqlen,
 	    pkt_node->th_seq,
 	    pkt_node->th_ack,
-	    pkt_node->data_sz);
+	    pkt_node->data_sz,
+	    pkt_node->fun_name,
+	    pkt_node->line,
+	    pkt_node->cubic_data.W_max,
+	    pkt_node->cubic_data.W_est,
+	    pkt_node->cubic_data.W_cubic);
 
 	if (ret_sz >= MAX_LOG_MSG_LEN) {
 		panic("%s: record size %d larger than max record size %d",
@@ -464,7 +479,7 @@ siftr_pkt_manager_thread(void *arg)
 						((STAILQ_NEXT(pkt_node, nodes) != NULL) ?
 							MAX_LOG_BATCH_SIZE : 1),
 					   ALQ_WAITOK);
- 
+
 			if (log_buf != NULL) {
 				log_buf->ae_bytesused = 0;
 				bufp = log_buf->ae_data;
@@ -601,6 +616,11 @@ siftr_siftdata(struct pkt_node *pn, struct inpcb *inp, struct tcpcb *tp,
 	pn->rcv_buf_cc = sbused(&inp->inp_socket->so_rcv);
 	pn->pipe = tcp_compute_pipe(tp);
 	pn->t_segqlen = tp->t_segqlen;
+	(void)strlcpy(pn->fun_name, tp->fun_name, sizeof(pn->fun_name));
+	pn->line = tp->line;
+	if (hash_node->const_info.tcp_cc == CUBIC) {
+		pn->cubic_data = *(struct cubic*)CC_DATA(tp);
+	}
 
 	/* We've finished accessing the tcb so release the lock. */
 	if (inp_locally_locked)
@@ -723,6 +743,13 @@ siftr_chkpkt(struct mbuf **m, struct ifnet *ifp, int flags,
 		} else if (tp->t_fb->tfb_tcp_block_name[0] == 'r') {
 			info.stack_type = RACK;
 		}
+
+		/* short hand for TCP congestion control check */
+		if (CC_ALGO(tp)->name[0] == 'c') {
+			info.tcp_cc = CUBIC;
+		} else if (CC_ALGO(tp)->name[0] == 'n') {
+			info.tcp_cc = NEWRENO;
+		}
 		info.mss = tcp_maxseg(tp);
 		info.sack_enabled = (tp->t_flags & TF_SACK_PERMIT) != 0;
 		info.snd_scale = tp->snd_scale;
@@ -971,11 +998,11 @@ siftr_manage_ops(uint8_t action)
 		qsort(arr, global_flow_cnt, sizeof(arr[0]), compare_nrecord);
 		sbuf_printf(s, "flow_list=");
 		for (j = 0; j < global_flow_cnt; j++) {
-			sbuf_printf(s, "%u,%s,%hu,%s,%hu,%d,%u,%u,%u,%u,%u,%u;",
+			sbuf_printf(s, "%u,%s,%hu,%s,%hu,%d,%d,%u,%u,%u,%u,%u,%u;",
 					arr[j].key,
 					arr[j].laddr, arr[j].lport,
 					arr[j].faddr, arr[j].fport,
-					arr[j].stack_type,
+					arr[j].stack_type, arr[j].tcp_cc,
 					arr[j].mss, arr[j].sack_enabled,
 					arr[j].snd_scale, arr[j].rcv_scale,
 					arr[j].nrecord, arr[j].ntrans);
